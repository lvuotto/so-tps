\documentclass[a4paper]{article}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{charter}   % tipografia
\usepackage{graphicx}
\usepackage{makeidx}

\usepackage{float}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{amsfonts}
\usepackage{sectsty}
\usepackage{wrapfig}
\usepackage{listings}
\usepackage{caption}

\usepackage{hyperref} %las entradas del índice tienen links
\hypersetup{
    colorlinks=true,
    linktoc=all,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\input{codesnippet}
\input{page.layout}
\usepackage{underscore}
\usepackage{caratula}
\usepackage{url}

\usepackage{color}
\usepackage{clrscode3e} % para el pseudocodigo




\begin{document}

\lstset{
  language=C++,
  backgroundcolor=\color{white},   % choose the background color
  basicstyle=\footnotesize,        % size of fonts used for the code
  breaklines=true,                 % automatic line breaking only at whitespace
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  keywordstyle=\color{blue},       % keyword style
  stringstyle=\color{mymauve},     % string literal style
}

\thispagestyle{empty}
\materia{Sistemas Operativos}
\submateria{Segundo Cuatrimestre de 2014}
\titulo{Trabajo Práctico III: Sistemas Distribuidos}
\integrante{Caravario, Martín}{470/12}{martin.caravario@gmail.com}
\integrante{Hosen, Federico}{825/12}{fhosen@hotmail.com}
\integrante{Vuotto, Lucas}{385/12}{lvuotto@dc.uba.ar}

\maketitle
\newpage

\thispagestyle{empty}
\vfill
\thispagestyle{empty}
\vspace{1.5cm}
\tableofcontents
\newpage


%\normalsize
\newpage
\section{Introducción}


\newpage
\section{Implementación Map-Reduce}

A la hora de llevar a cabo las implementaciones de las funciones \textit{map},
\textit{reduce} y \textit{finalize} de cada ejercicio, se optó por crear
archivos distintos a los provistos por la cátedra para satisfacer necesidades
de flexibilidad a la hora de generar y manipular los resultados.

Se adjunta un \verb|Makefile| en la entrega con el objetivo de facilitar la
ejecución de los ejercicio solicitados. Los objetivos del mismo son:
\begin{itemize}
  \item \verb|all|, objetivo por defecto, que se encarga de crear la base de
  datos con todas sus entradas y ejecutar los ejercicios,
  \item \verb|run|, que solo corre los ejercicios, asumiendo que la base de
  datos fue creada,
  \item \verb|db|, que solo crea la base de datos, y
  \item \verb|run-ejN|, donde N toma un valor del 1 al 5, que solo corre el
  ejercicio N.
\end{itemize}

\subsection{Ejercicio 1}
En este ejercicio se pide obtener el \textit{subreddit} con la mayor cantidad
de puntaje. Para lograrlo, se implementaron las funciones \textit{map},
\textit{reduce} y \textit{finalize} del siguiente modo:
\begin{itemize}
  \item \verb|map()|: genera una estructura con los campos \verb|puntaje|, que
  vale el puntaje que tiene el post, y \verb|cantidad|, que se utilizará para
  guardar la cantidad de post que tiene cada \textit{subreddit}, tomando el
  valor inicial $1$. Esta estructura es emitida para ser procesado por el
  \textit{reduce} usando el nombre del \textit{subreddit} como clave.
  \item \verb|reduce(k, v)|: genera una estructura estructura con mismos campo
  que la generada en la función \verb|map| que se utilizará para acumular
  resultados, iniciando sus campos en $0$. Luego se recorre el arreglo
  \verb|v| y se suman los puntajes y las cantidades con los de la estructura
  utilizada para acumulación. Esto permite mantener los 3 aspectos necesarios
  de la función \textit{reduce}: la asociatividad y conmutatividad se
  desprenden de la suma y la idempotencia proviene del hecho de inicializar los
  campos en $0$ antes de realizar las operaciones de acumulación.
  \item \verb|finalize(k, rv)|: solamente retorna la división entra la
  sumatoria de los puntajes y la cantidad de entradas como único valor asociado
  a la clave, es decir, al \textit{subreddit} en cuestión.
\end{itemize}

El resultado de aplicar el proceso de \textit{map-reduce} es volcado a una
colección llamada \textbf{ej1}. Esta es recorrida linealmente para encontrar la
entrada con mayor valor en el campo \verb|value|, que, como se explico
previamente, tiene el puntaje promedio \textbf{por entrada} de cada
\textit{subreddit}. Luego, para obtener el \textit{subreddit} con mayor puntaje
promedio por entrada, solo basta ver la clave del primer documento de la
colección para saber cuál es el \textit{subreddit} buscado.

\subsection{Ejercicio 2}
En este ejercicio se quiere saber la los doce títulos con mayor puntaje,
siempre y cuando este supere los $2000$ puntos. Para la realización se
implementaron las funciones \textit{map}, \textit{reduce} y \textit{finalize}
del siguiente modo:
\begin{itemize}
  \item \verb|map()|: se descartan las entradas con menos de $2000$ votos en
  total. Con las entradas no descartadas, se genera una estructura
  \textit{acumuladora} con un único campo \verb|arreglo|, la cual posée un
  arreglo de estructuras formado por una única estructura con campos
  \verb|titulo| y \verb|puntaje|, inicializados en el título y el puntaje del
  post, respectivamente. Luego, esta estructura acumuladora es emitida con la
  clave ``\verb|mas_de_2000|''. Esto se realiza para poder luego acumular todas
  las entradas y ordenarlas.
  \item \verb|reduce(k, v)|: genera un arreglo vacío \verb|r| y se recorre el
  arreglo \verb|v|, concatenándole a \verb|r| los campos \verb|arreglo| de cada
  ítem del arreglo \verb|v|, para finalmente devolver una nuevo estructura
  acumuladora en la cual su campo \verb|arreglo| valdrá \verb|r|. De este modo,
  se logra emitir un único resultado en el proceso de \textit{map-reduce}, la
  cual tendrá como clave ``\verb|mas_de_2000|'' y, como valor, un arreglo en el
  cual están presentes todos los posts con más de $2000$ votos. Los 3
  requerimientos de la función \textit{reduce} son mantenidos: la asociatividad
  y la conmutatividad se desprenden de la concatenación (si se consideran a los
  arreglos como conjuntos y la concatenación como únion, que es el caso, pues
  el ordenamiento necesarios para obtener a los 12 mejores se realiza en la
  función \textit{finalize}) y la idempotencia se obtiene al inicializar la
  variable de acumulación \verb|r| como un arreglo vacío.
  \item \verb|finalize(k, rv)|: el parámetro \verb|rv| de la función contiene
  una estructura acumuladora cuyo campo \verb|arreglo| consta con el título y
  el puntaje de \textbf{todos} los posts con al menos $2000$ votos. Este
  arreglo es ordenado por puntaje y se extraen los 12 mejores. Con estos se
  crea un nuevo arreglo que solo contiene los título de esos posts, obtienendo
  así el resultado buscado.
\end{itemize}

El resultado de aplicar el proceso de \textit{map-reduce} es volcado a una
colección llamada \textbf{ej2} y se imprime el valor de la única entrada que
puede tener dicha colección. Dicho valor es una arreglo con a los títulos
buscados, separados por saltos de línea.

\subsection{Ejercicio 3}
El objetivo de este ejercicio es obtener la cantidad promedio de comentarios de
los 10 posts con mayor puntaje. Para obtener este valor, se implementaron las
funciones \textit{map}, \textit{reduce} y \textit{finalize} de la siguiente
manera:
\begin{itemize}
  \item \verb|map()|: se emplea la misma estrategia de crear una estructura
  acumuladora del mismo modo que el visto en el \textbf{ejercicio 2} y se emite
  dicha estructura junto con la clave ``\verb|por_puntaje|''.
  \item \verb|reduce(k, v)|: de nuevo se realiza el mismo procedimiento que en
  la función \textit{reduce} del \textbf{ejercicio 2}. Sin embargo, antes de
  retornar la estructura acumuladora, el arreglo \verb|r| es ordenado
  decrecientemente por puntaje y solo se conservan sus 10 primeros elementos.
  Aún con este cambio se siguen cumpliendo los requerimientos de la función
  \textit{reduce}: es idempotente, pues \verb|r| comienza vacío y no se
  producen inserciones en el parámetro de entrada, es conmutativa, pues $A \cup
  B$ tiene los mismos elementos $B \cup A$, pese al orden, y es asociativa,
  pues tomar el máximo sobre 3 conjuntos es lo mismo que tomar el máximo entre
  2 conjuntos y compararlo contra el máximo del otro conjunto.
  \item \verb|reduce(k, rv)|: de nuevo, \verb|rv| contiene ahora un arreglo que
  contiene los 10 (o menos) posts con mayor puntaje. Solo se retorna el
  promedio de la sumatoria de la cantidad de comentarios.
\end{itemize}

El resultado de aplicar el proceso de \textit{map-reduce} es volcado a una
colección llamada \textbf{ej3} y se imprime el valor de la única entrada que
puede o tener dicha colección.

\subsection{Ejercicio 4}
El fin de este ejercicio es encontrar al usuario con mayor cantidad de
\textit{upvotes} entre todos los usuarios que realizaron como máximo 5 posts.
Para cumplir dicho fin, se implementaron solamente las funciones \textit{map} y
\textit{reduce} del siguiente modo:
\begin{itemize}
  \item \verb|map()|: se genera una estructura con un campo \verb|votos|,
  inicializado en la cantidad de \textit{upvotes} del posts, y un campo
  \verb|cantidad|, que se utilizará para acumular la cantidad de posts del
  usuario, inicializado en $1$. Esta estructura se emite utilizando como clave
  el nombre del usuario que creó el post.
  \item \verb|reduce(k, v)|: se genera una estructura \verb|r| con los campos
  \verb|votos| y \verb|cantidad| inicializados en $0$. Esta estructura se usa
  para acumular la cantidad de votos y la cantidad de posts del usuario
  \verb|k|. Una vez realizada la acumulación, si la cantidad de posts de
  usuario es mayor a $5$, se marca como inválido el usuario, seteando su
  cantidad de votos en $-1$. Esto cumple con los requerimientos de la función
  \textit{reduce}, pues solo se realizan sumas y el valor del campo
  \verb|cantidad| nunca es negativo, por lo que una vez que se supera el valor
  $5$, consecuentemente se seguirá superando, asegurando la idempotencia.
\end{itemize}

El resultado de aplicar el proceso de \textit{map-reduce} es volcado a una
colección llamada \textbf{ej4}, en la cual se filtran los resultados y solo se
tienen en cuenta los registros cuya cantidad de votos es \textbf{mayor} a $-1$,
es decir, los registros pertenecientes a aquellos usuarios que tienen a lo sume
5 posts y luego es recorrida linealmente para obtener la entrada con mayor
valor del campo \verb|votos|. Una vez hecho esto, se imprime la clave
correspondiente al primer valor, es decir, el nombre de usuario.

\subsection{Ejercicio 5}
En este ejercicio se pide encontrar la cantidad de palabras presentes en el
título de cada los posts de los \textit{subreddits} cuyo puntaje se encuentre
entre 280 y 300. Para obtener este resultado, se implementaron las funciones
\textit{map}, \textit{reduce} y \textit{finalize} del siguiente modo:
\begin{itemize}
  \item \verb|map()|: se crea una estructura con campos \verb|puntaje|,
  inicializado en el puntaje del post, y \verb|palabras|, inicializado en la
  cantidad de palabras del título del posts. Se considera como palabra todo
  secuencia de caracteres no correspondientes a espacios en blanco (es decir,
  espacio, tabulador, salto de línea, etc.). Esta estructura es emitida
  utilizando como clave el nombre del \textit{subreddit} al que pertenece el
  post.
  \item \verb|reduce(k, v)|: se crea una estructura de acumulación en la cual
  se suman los puntajes y la cantidad de palabras de los posts del
  \textit{subreddit} \verb|k|. Como ya se demostró, como solo se realizan sumas
  y los valores iniciales son $0$, se conservan las propiedades que debe
  cumplir la función \textit{reduce}.
  \item \verb|finalize(k, rv)|: solo se chequea si el puntaje se encuentra en
  rango. Si es así, se devuelve la cantidad de palabras de los títulos de todos
  los posts del \textit{subreddit}. Caso contrario, se invalida el resultado
  retornando $-1$.
\end{itemize}

El resultado de aplicar el proceso de \textit{map-reduce} es volcado a una
colección llamada \textbf{ej5}. En esta se filtran los resultados que tengan el
campo \verb|value| (la cantidad de palabras en el título) el valor $-1$, es
decir, se dejan de lado aquellos \textit{subreddits} cuyo puntaje \textbf{no}
se encuentre entre 280 y 300. Los \textit{sureddits} restantes son ordenados
decrecientemente e impresos.

\newpage
\section{Investigación}

La motivación del paper nace a partir de utilizar el paradigma
\textit{map-reduce} en grandes clusters compartidos entre varios usuarios, dado
que concentrar largos volúmenes de datos en un mismo cluster es económicamente
más barato que tener clusters privados para cada usuario, y el benificio a la
hora de realizar diversas tareas, como podría ser data-minning o búsqueda de
spam, aumenta considerablemente.

El problema es que al momento de administrar los recursos, el scheduler
implementado hasta el momento presenta algunos problemas que reducen de forma
considerable el rendimiento al correr ciertos tipos de trabajos. Concretamente,
el problema se da al correr grandes trabajos en conjunto con \textit{queries},
es decir, trabajos de interacción con el usuario donde es importante el tiempo
de respuesta, y no sólo el \textit{throughput}. Sin embargo, al tratar de
encarar el problema concreto de \textit{scheduling} surgen dos incovenientes
más, inherentes al paradigma \textit{map-reduce} en clusters multiusuario: la
localía de datos, es decir, la necesidad de correr tareas sobre datos
almacenados localmente, en contraposición a utilizar datos que no se encuentran
disponibles en el mismo lugar físico, para poder así ganar performance y
aumentar el \textit{throughput}, y la interdepencia entre \textit{reduce} y
\textit{map}, es decir, el tener que esperar obligatoriamente la finalización
de la función \textit{map} para poder terminar de ejecutar la función
\textit{reduce}.

El scheduler usado hasta el momento es el \textit{Hadoop's FIFO scheduler}, que
básicamente utiliza una política \textbf{FIFO} con cinco niveles de
privilegios.  Como hemos visto en las clases, éste tipo de política es poco
justo con respecto a las tareas cortas e interactivas, pues si ya están
encoladas grandes tareas que insumen mucho tiempo de recursos, estas tareas
cortas deberán esperar mucho tiempo para correr, disminuyendo considerablemente
el tiempo de respuesta.

Una primera aproximación a la solución es Hadoop On Demand (HOD), que establece
clusters virtuales\footnote{Llamamos cluster virtual a un conjunto de nodos
agrupados que el usuario ve como un cluster privado.} fijos para cada usuario.
El problema que conlleva dicha solución es que al tener los datos distribuidos
por todo el cluster (pues así funciona HDFS) al querer acceder a un dato que no
está en uno de los nodos del cluster privado asignado, se disminuye el
\textit{throughput} y el tiempo de respuesta, pues al buscar el dato fuera del
nodo, el tiempo de acceso es mayor.

Sin embargo, el problema mencionado anteriormente no es el único, al distribuir
los recursos de forma estática en cada cluster privado, cuando los nodos no
están siendo utilizados no pueden ser reasignados a otros trabajos,
desperdiciando así recursos del cluster.

Para mitigar los problemas descriptos previamente, los autores del paper
proponen una política de \textit{scheduling} llamada \textbf{FAIR}, la cual
plantea 2 objetivos principales.
\begin{itemize}
  \item \textbf{isolation}, proveer a cada usuario un cluster virtual para
  generar la ilusión de disponer de un cluster privado, y
	\item \textbf{statistical multiplexing}, reasignar dinámicamente los recursos
  inutilizados.
\end{itemize}

Para lograr esto, se propone un sistema de jerarquías de 2 niveles de
distribución de recursos: entre \textit{pools} de tareas, a nivel global, y
entre tareas, a nivel de cada \textit{pool}. Los \textit{pools} son
abstracciones utilizadas por el \textit{scheduler} para agrupar recursos y cada
uno cuenta con una cantidad mínima de recursos necesarios y una demanda de
recursos. El model garantiza que cada \textit{pool} reciba su cantidad mínima
de recursos (a menos que la demanda sea menor a esta cantidad), ya que este
valor se elige cumpliendo que la suma de la cantidad mínima de recursos de cada
\textit{pool} no supere la capacidad total del sistema.

El \textit{scheduler} asigna los recursos en 3 pasos:
\begin{enumerate}
	\item A todos los \textit{pools} cuya demanda sea menor a la cantidad mínima
  recursos, se les asigna tantos recursos como demanda tengan.
	\item Al resto de los \textit{pools} se les asigna tantos recursos como
  cantidad mínima necesiten. Esto da la sensación a los usuarios de operar
  sobre un cluster privado, pues cada \textit{pool} tiene o bien los recursos
  necesarios para satisfacer su demanda o bien la cantidad mínima de recursos
  necesitados, logrando el objetivo de \textbf{isolation}.
	\item Se distribuyen los recursos restantes hasta llegar a satisfacer la
  demanda o agotar los recursos, siendo los \textit{pools} de menor cantidad de
  recursos adquiridos los primeros en recibir este beneficio. Esto cumple con
  el objetivo de \textbf{statistical multiplexing}, pues cuando la demanda de
  un \textit{pool} no supera su mínimo de recursos, los recursos sobrantes no
  se utilizarían y esto paso permite redistribuirlos.
\end{enumerate}

A la hora de reasignar recursos frente a la llegada de un nuevo trabajo y
nuevas demandas, el \textit{scheduler} necesita liberar y reasignar recursos de
los \textit{pools} para el nuevo trabajo en un tiempo relativamente corto, con
el fin de mantener el objetivo de \textbf{isolation}. Para lograr esto, se
establecen 2 tiempos límites: $T_{min}$ y $T_{fair}$, donde $T_{min}$ es el
tiempo a esperar para matar tareas para y obtener recursos, si es que el nuevo
trabajo no los tenía, y $T_{fair}$ es el tiempo a esperar luego de haberse
cumplido $T_{min}$ para matar más tareas en caso de no tener disponibles la
cantidad de recursos justos para el nuevo trabajo. De este modo, el trabajo
empieza a correr tan pronto como lo haría en un cluster privado. Cabe destacar
que, al matar a una tarea para asignar sus recursos a un nuevo trabajo, se
disminuye el \textit{throughput}.



\newpage
\section{Conclusión}


\end{document}
